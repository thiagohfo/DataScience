{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importando as bibliotecas essenciais\n",
    "\n",
    "Todas as bibliotecas importadas a seguir, são indispensáveis para o pré-processamento dos dados, sendo Pandas a principal delas. Nela está contida todas as formas de manipularmos dados. Também é importada a biblioteca NumPy, útil para operações com arrays.\n",
    "\n",
    "Link do Pandas: https://pandas.pydata.org\n",
    "Link do Chardet: https://pypi.org/project/chardet/\n",
    "Link da NumPy: https://numpy.org"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet as chardet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Leitura da base\n",
    "\n",
    "A base a ser utilizada deve ser lida pelo Pandas, identificando o seu real formato, permitindo assim que a mesma possa ser lida integralmente e sem a possibilidade de erros.\n",
    "\n",
    "Link da função read_csv: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Mostrar todas as colunas\n",
    "pd.set_option('display.max_rows', 30)  # Mostrar apenas 10 linhas\n",
    "\n",
    "with open('AP.csv', 'rb') as check_raw:\n",
    "    raw_data = check_raw.readline()\n",
    "    encode = chardet.detect(raw_data).get('encoding')\n",
    "    if encode == 'ascii':\n",
    "        encode = 'utf-8'\n",
    "\n",
    "df = pd.read_csv('AP.csv', encoding=encode, sep=None, on_bad_lines='skip', engine='python')\n",
    "\n",
    "print(\"Tamanho da base: {}\".format(len(df)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exibição da base\n",
    "\n",
    "Uma vez que a base foi lida com sucesso, nós devemos sempre analisar como ela está disposta e a partir disso, tomarmos as decisões para posteriores limpezas necessárias."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head() # Por padrão, a função head() mostra apenas 5 linhas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Breve descrição do problema\n",
    "\n",
    "O objetivo proposto é uma análise sobre os sintomas, buscando uma correlação entre os mesmos e a possibilidade de estar infectado pelo COVID-19. Além disto, o problema também tem como objetivo secundário tentar predizer um prognóstico a respeito do grau de severidade com a qual a doença pode atingí-lo. Para isso, se faz necessário trabalhar apenas em cima de dados essenciais, tais como sintomas, comorbidades e outros dados que já são sabidamente influentes com relação a doença."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum() # Indentificando dados nulos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()/len(df)*100 # Porcentagem em uma escala de 100%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Formas de tratar dados faltantes\n",
    "\n",
    "Existem algumas formas de tratar dados faltantes, as principais são:\n",
    "- Valores numéricos: usar a média dos valores para a coluna\n",
    "- Valores categóricos: usar o valor que mais aparece (moda)\n",
    "- Ignorar essas linhas\n",
    "\n",
    "# As funções que podem corresponder a estas medidas são:\n",
    "- fillna(parâmetro), preenche valores faltantes com o parâmetro passado\n",
    "- interpolate(), preenche o valor com base na interpolação dos valores anterior e seguinte. Link: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Eliminando rows com valores nulos em colunas essenciais\n",
    "\n",
    "As colunas definidas são de extrema importância para que os dados possam ser precisos, ainda mais pelo tipo do problema que está sendo tratado."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Colunas para analisar os dados e deletar as amostras (rows)\n",
    "\n",
    "columns_analyze = ['evolucaoCaso', 'sintomas', 'tipoTeste', 'resultadoTeste', 'classificacaoFinal']\n",
    "df.dropna(how='any', subset=columns_analyze, inplace=True)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algumas correções necessárias\n",
    "\n",
    "Algumas correções se fazem necessária pela falta de padrão em alguns preenchimentos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# No problema, os testes de antígenos são considerados com a mesma eficácia que os RT-PCR\n",
    "df['tipoTeste'].replace(to_replace='TESTE RÁPIDO - ANTÍGENO', value='RT-PCR', inplace=True)\n",
    "df.drop(df[df['tipoTeste'] != 'RT-PCR'].index, inplace=True) # Dropo todas os testes que sejam diferentes de RT-PCR\n",
    "# Todos os casos diferentes de confirmados são deletados\n",
    "df.drop(df[~df['classificacaoFinal'].str.contains(r'Confirmado')].index, inplace=True)\n",
    "# Todos os resultados do teste que deram inconclusivos ou incompletos são descartados\n",
    "df.drop(df[df['resultadoTeste'].str.contains(r'^[In].*')].index, inplace=True)\n",
    "# Evoluções consideradas canceladas ou ignoradas são deletadas\n",
    "df.drop(df[(df['evolucaoCaso'] == 'Cancelado') | (df['evolucaoCaso'] == 'Ignorado')].index, inplace=True)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mais algumas correções sobre dados inconsistentes\n",
    "\n",
    "Alguns dados não foram devidamente preenchidos, tais como quantidade de dias com sintomas e alguns outros e os mesmos são consertados via os seguintes códigos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dates_filling(raw_df_t, *columns): # Preenche as datas faltantes\n",
    "    if pd.isnull(raw_df_t.loc[columns[0]]) & pd.notnull(raw_df_t.loc[columns[1]]):\n",
    "        raw_df_t[columns[0]] = raw_df_t[columns[1]]\n",
    "    elif pd.notnull(raw_df_t.loc[columns[0]]) & pd.isnull(raw_df_t.loc[columns[1]]):\n",
    "        raw_df_t[columns[1]] = raw_df_t[columns[0]]\n",
    "    elif pd.isnull(raw_df_t.loc[columns[0]]) & pd.isnull(raw_df_t.loc[columns[1]]):\n",
    "        raw_df_t[columns[0]] = pd.to_datetime('today', format='%Y-%m-%d')\n",
    "        raw_df_t[columns[1]] = pd.to_datetime('today', format='%Y-%m-%d')\n",
    "\n",
    "    return raw_df_t\n",
    "\n",
    "# Correção, muda valores de null para empty strings.\n",
    "df['condicoes'].fillna('', inplace=True)\n",
    "df['outrosSintomas'].fillna('', inplace=True)\n",
    "\n",
    "# Consertando um probleminha de datas com valores ausentes para poder aplicar funções\n",
    "df = df.apply(dates_filling, args=['dataNotificacao', 'dataInicioSintomas'], axis=1)\n",
    "data_notificacao = pd.to_datetime(df['dataNotificacao'], errors='coerce', format='%Y-%m-%d')\n",
    "data_inicio_sintomas = pd.to_datetime(df['dataInicioSintomas'], errors='coerce', format='%Y-%m-%d')\n",
    "df.insert(0, \"diasSintomas\", (data_notificacao - data_inicio_sintomas).dt.days, True)\n",
    "df.loc[df['diasSintomas'] < 0, 'diasSintomas'] = df['diasSintomas'] * -1\n",
    "df.drop(df[df['diasSintomas'] > 90].index, inplace=True)\n",
    "\n",
    "# Colunas para deletar\n",
    "columns_del = ['id', 'estadoNotificacao', 'estadoNotificacaoIBGE', 'municipioNotificacao',\n",
    "               'municipioNotificacaoIBGE', 'profissionalSaude', 'profissionalSeguranca', 'cbo', 'sexo', 'racaCor',\n",
    "               'estado', 'estadoIBGE', 'municipio', 'municipioIBGE', 'dataNotificacao', 'dataInicioSintomas',\n",
    "               'estadoTeste', 'dataTeste', 'dataEncerramento', 'cnes']\n",
    "\n",
    "# Deletando atributos irrelevantes para análise\n",
    "df.drop(columns_del, axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformando informações de linha em colunas\n",
    "\n",
    "Os sintomas, outros sintomas e comorbidades foram preenchidos de forma na qual eles ficam agrupados, assim, fica impossibilitado de trabalharmos com eles como features, sendo necessário transformar eles em colunas para que seja possível atuar diretamente sobre esses dados."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re # Biblioteca para aplicação de Regex\n",
    "from unidecode import unidecode # Biblioteca para extrair caracteres com acentos especiais\n",
    "\n",
    "# Sintomas e condições para virarem colunas\n",
    "datas = {'other_symptoms': {'mialgia': ['mialgia', 'corpo', 'muscular'],\n",
    "                            'cabeca': ['cefaleia', 'cabeca'],\n",
    "                            'fadiga': ['fadiga', 'cansaco', 'fraqueza', 'indisposicao', 'adinamia', 'moleza',\n",
    "                                       'astenia'],\n",
    "                            'nauseas': ['nausea', 'nauseas', 'tontura', 'mal estar', 'enjoo'],\n",
    "                            'coriza': ['coriza'],\n",
    "                            'anosmia': ['olfato', 'anosmia', 'hiposmia'],\n",
    "                            'hipogeusia': ['paladar', 'hipogeusia', 'disgeusia'],\n",
    "                            'diarreia': ['diarreia'], 'febre': ['febre', 'febril'],\n",
    "                            'tosse': ['tosse']\n",
    "                            },\n",
    "         'symptoms': ['tosse', 'febre', 'garganta', 'dispneia', 'cabeca', 'coriza', 'hipogeusia', 'anosmia',\n",
    "                      'fadiga', 'nauseas', 'mialgia', 'diarreia'],\n",
    "         'conditions': ['cardiacas', 'diabetes', 'respiratorias', 'renais', 'imunologica', 'obesidade',\n",
    "                        'imunossupressao', 'gestante', 'puerpera']\n",
    "        }\n",
    "\n",
    "columns = datas['symptoms'] + [col for col in datas['other_symptoms'].keys() if col not in datas['symptoms']] + datas['conditions']\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    df.insert((i + 1), column, '', True)\n",
    "\n",
    "def standarding_features(raw_df_t, *features, **kwargs):\n",
    "    column = kwargs['key']\n",
    "\n",
    "    if not raw_df_t[column].strip():\n",
    "        for i in features:\n",
    "            raw_df_t[i] = 0  # Remover aqui se for para não preencher com 0 em valores faltosos\n",
    "        return raw_df_t\n",
    "    else:\n",
    "        for i in features:\n",
    "            if re.search(i, unidecode(raw_df_t[column]).strip().lower()):  # Retira todos os caracteres especiais\n",
    "                raw_df_t[i] = 1\n",
    "            else:\n",
    "                raw_df_t[i] = 0  # Remover aqui se for para não preencher com 0 em valores faltosos\n",
    "\n",
    "    return raw_df_t\n",
    "\n",
    "# Preenche as colunas dos sintomas e condicoes com 1\n",
    "for feature, column in zip([datas['symptoms'], datas['conditions']], ['sintomas', 'condicoes']):\n",
    "    df = df.apply(standarding_features, axis=1, args=feature, key=column)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agora operando sobre os outros sintomas\n",
    "\n",
    "Os outros sintomas também foram colocados como um vetor, impossibilitando assim que eles sejam usados como colunas para que possam ser usados como dados para ajudar na inferência do problema."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Outros sintomas e condições para virarem colunas\n",
    "def standarding_features_with_dict(raw_df_t, *column, **kwargs):\n",
    "    kwargs = kwargs['key']\n",
    "\n",
    "    if not raw_df_t[column[0]].strip():\n",
    "        for key in kwargs.keys():\n",
    "            if not raw_df_t[key]:\n",
    "                raw_df_t[key] = 0  # Remover aqui se for para não preencher com 0 em valores faltosos\n",
    "        return raw_df_t\n",
    "    else:\n",
    "        for key in kwargs.keys():\n",
    "            for value in kwargs[key]:\n",
    "                if raw_df_t[key] == 1:\n",
    "                    break\n",
    "                elif re.search(value, unidecode(str(raw_df_t[column[0]])).strip().lower()):  # Retira caract. especiais\n",
    "                    raw_df_t[key] = 1\n",
    "                    break\n",
    "                else:\n",
    "                    raw_df_t[key] = 0  # Remover aqui se for para não preencher com 0 em valores faltosos\n",
    "\n",
    "    return raw_df_t\n",
    "\n",
    "df = df.apply(standarding_features_with_dict, axis=1, args=['outrosSintomas'], key=datas['other_symptoms'])\n",
    "df.drop(['sintomas', 'condicoes', 'outrosSintomas'], axis=1, inplace=True)\n",
    "df.drop(df[(df[datas['symptoms']] == 0).all(axis=1)].index, inplace=True)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Última etapa do processamento para esta base\n",
    "\n",
    "Como última etapa, iremos agregar alguns valores e substituir outros para que a nossa base fique totalmente adequada para ser trabalhada com algoritmos de aprendizagem por reforço, visando a melhor forma possível de se obter predições."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trocar alguns valores\n",
    "cols_change = ['resultadoTeste', 'evolucaoCaso']  # Índice 0 no zip\n",
    "old_values = [['Negativo', 'Positivo'], [r'.*tratamento.*', r'Internado.*']]  # Índice 1 no zip\n",
    "new_values = [[0, 1], ['Cura', 'Internado']]  # Índice 2 no zip\n",
    "use_regex = [False, True]  # Índice 3 no zip\n",
    "\n",
    "for values in zip(cols_change, old_values, new_values, use_regex):\n",
    "    df[values[0]].replace(to_replace=values[1][0], value=values[2][0], regex=values[3], inplace=True)\n",
    "    df[values[0]].replace(to_replace=values[1][1], value=values[2][1], regex=values[3], inplace=True)\n",
    "\n",
    "for col in ['idade', 'diasSintomas']:\n",
    "    df.drop(df[df[col].isin([np.nan, np.inf, -np.inf])].index, inplace=True)\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Salvando a base pré-processada\n",
    "\n",
    "Uma vez feito o processo de pré-processamento, agora salvamos a base para atuarmos diretamente em cima da base já consolidadamente limpa, apenas com as informações que nos sejam relevantes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('AP_processed.csv', sep=';', encoding='utf-8', index=False) # Salvando a base em arquivo CSV\n",
    "print(\"Tamanho da base: {}\".format(len(df)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
